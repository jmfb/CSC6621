{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68988eec-b1fa-4e13-b081-ffb2b355ce5e",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "* **Project:** M2: Mini Project\n",
    "* **AUthor** Jacob Buysse\n",
    "\n",
    "In this project we are going to analyze the impact of feature engineering on model performance.  I have chosen a dataset containing 13 features and one target class for determining if heart disease is present in the patient.<br>\n",
    "https://archive.ics.uci.edu/dataset/45/heart+disease\n",
    "\n",
    "In this notebook we will be using..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db35b99d-b6b8-48a2-acf9-8f950cd93c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476bd3f7-2dcf-48e9-9cb2-46ee3c50aee2",
   "metadata": {},
   "source": [
    "Let is load the cleveland data file and view the head/info/describe results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66356126-d019-4206-a767-309a4c19ce45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0  63.0  1.0  1.0     145.0  233.0  1.0      2.0    150.0    0.0      2.3   \n",
       "1  67.0  1.0  4.0     160.0  286.0  0.0      2.0    108.0    1.0      1.5   \n",
       "2  67.0  1.0  4.0     120.0  229.0  0.0      2.0    129.0    1.0      2.6   \n",
       "3  37.0  1.0  3.0     130.0  250.0  0.0      0.0    187.0    0.0      3.5   \n",
       "4  41.0  0.0  2.0     130.0  204.0  0.0      2.0    172.0    0.0      1.4   \n",
       "\n",
       "   slope   ca  thal  num  \n",
       "0    3.0  0.0   6.0    0  \n",
       "1    2.0  3.0   3.0    2  \n",
       "2    2.0  2.0   7.0    1  \n",
       "3    3.0  0.0   3.0    0  \n",
       "4    1.0  0.0   3.0    0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    './processed.cleveland.data',\n",
    "    names=[\n",
    "        'age', 'sex', 'cp', 'trestbps', 'chol',\n",
    "        'fbs', 'restecg', 'thalach', 'exang', 'oldpeak',\n",
    "        'slope', 'ca', 'thal', 'num'\n",
    "    ],\n",
    "    dtype={'ca': np.float64, 'thal': np.float64},\n",
    "    na_values={'ca': ['?'], 'thal': ['?']}\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e46bc215-aba9-49bf-9557-fb8c0f34af34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       303 non-null    float64\n",
      " 1   sex       303 non-null    float64\n",
      " 2   cp        303 non-null    float64\n",
      " 3   trestbps  303 non-null    float64\n",
      " 4   chol      303 non-null    float64\n",
      " 5   fbs       303 non-null    float64\n",
      " 6   restecg   303 non-null    float64\n",
      " 7   thalach   303 non-null    float64\n",
      " 8   exang     303 non-null    float64\n",
      " 9   oldpeak   303 non-null    float64\n",
      " 10  slope     303 non-null    float64\n",
      " 11  ca        299 non-null    float64\n",
      " 12  thal      301 non-null    float64\n",
      " 13  num       303 non-null    int64  \n",
      "dtypes: float64(13), int64(1)\n",
      "memory usage: 33.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17643095-0e9f-43a3-8c34-4913a684ad4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>301.000000</td>\n",
       "      <td>303.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.438944</td>\n",
       "      <td>0.679868</td>\n",
       "      <td>3.158416</td>\n",
       "      <td>131.689769</td>\n",
       "      <td>246.693069</td>\n",
       "      <td>0.148515</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>149.607261</td>\n",
       "      <td>0.326733</td>\n",
       "      <td>1.039604</td>\n",
       "      <td>1.600660</td>\n",
       "      <td>0.672241</td>\n",
       "      <td>4.734219</td>\n",
       "      <td>0.937294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.038662</td>\n",
       "      <td>0.467299</td>\n",
       "      <td>0.960126</td>\n",
       "      <td>17.599748</td>\n",
       "      <td>51.776918</td>\n",
       "      <td>0.356198</td>\n",
       "      <td>0.994971</td>\n",
       "      <td>22.875003</td>\n",
       "      <td>0.469794</td>\n",
       "      <td>1.161075</td>\n",
       "      <td>0.616226</td>\n",
       "      <td>0.937438</td>\n",
       "      <td>1.939706</td>\n",
       "      <td>1.228536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>133.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>241.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>275.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age         sex          cp    trestbps        chol         fbs  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean    54.438944    0.679868    3.158416  131.689769  246.693069    0.148515   \n",
       "std      9.038662    0.467299    0.960126   17.599748   51.776918    0.356198   \n",
       "min     29.000000    0.000000    1.000000   94.000000  126.000000    0.000000   \n",
       "25%     48.000000    0.000000    3.000000  120.000000  211.000000    0.000000   \n",
       "50%     56.000000    1.000000    3.000000  130.000000  241.000000    0.000000   \n",
       "75%     61.000000    1.000000    4.000000  140.000000  275.000000    0.000000   \n",
       "max     77.000000    1.000000    4.000000  200.000000  564.000000    1.000000   \n",
       "\n",
       "          restecg     thalach       exang     oldpeak       slope          ca  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  299.000000   \n",
       "mean     0.990099  149.607261    0.326733    1.039604    1.600660    0.672241   \n",
       "std      0.994971   22.875003    0.469794    1.161075    0.616226    0.937438   \n",
       "min      0.000000   71.000000    0.000000    0.000000    1.000000    0.000000   \n",
       "25%      0.000000  133.500000    0.000000    0.000000    1.000000    0.000000   \n",
       "50%      1.000000  153.000000    0.000000    0.800000    2.000000    0.000000   \n",
       "75%      2.000000  166.000000    1.000000    1.600000    2.000000    1.000000   \n",
       "max      2.000000  202.000000    1.000000    6.200000    3.000000    3.000000   \n",
       "\n",
       "             thal         num  \n",
       "count  301.000000  303.000000  \n",
       "mean     4.734219    0.937294  \n",
       "std      1.939706    1.228536  \n",
       "min      3.000000    0.000000  \n",
       "25%      3.000000    0.000000  \n",
       "50%      3.000000    0.000000  \n",
       "75%      7.000000    2.000000  \n",
       "max      7.000000    4.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1090afd-99ca-4ad7-b58f-580a184046e5",
   "metadata": {},
   "source": [
    "We have 303 rows.  There are 4 NA (?) values for `ca` and 2 NA (?) values for `thal`.  All values were loaded as `float64` though quite a few are listed as categorical on the source website.\n",
    "\n",
    "Let us take a closer look at the target value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0017eb94-3269-48ff-a364-65c79cadeec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num\n",
       "0    164\n",
       "1     55\n",
       "2     36\n",
       "3     35\n",
       "4     13\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.num.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60985e3-1bea-4262-8978-6c4fa81ee383",
   "metadata": {},
   "source": [
    "It is described as a categorical value with 0 being the absence of heart disease and values 1 through 4 being different degrees of heart disease being present.  However, we can just try to compute a binary classifier for absense (0) or presence (1-4).  Let us add the new target column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e9e5ad2-affa-4d84-b46a-664c56e422c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       303\n",
       "unique        2\n",
       "top       False\n",
       "freq        164\n",
       "Name: disease, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['disease'] = df.num.apply(lambda value: value != 0)\n",
    "df.disease.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19367dc-3597-49fa-8117-12a83a16d719",
   "metadata": {},
   "source": [
    "So we have 164 samples with no heart disease and 139 samples with heart disease.  Let us do an 75/25 train/test split stratified over the binary classifier and try a logistic regression to get a baseline performance before doing any feature engineering.  We will just drop the NA rows for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d60630c7-eb18-4477-814c-048076e0b023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train 222, X_test 75, y_train 222, y_test 75\n"
     ]
    }
   ],
   "source": [
    "features = [\n",
    "    'age', 'sex', 'cp', 'trestbps', 'chol',\n",
    "    'fbs', 'restecg', 'thalach', 'exang', 'oldpeak',\n",
    "    'slope', 'ca', 'thal'\n",
    "]\n",
    "filtered_df = df.dropna()\n",
    "X = filtered_df[features].values\n",
    "y = filtered_df.disease.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=777, stratify=filtered_df.disease)\n",
    "\n",
    "def score_model(y_pred):\n",
    "    print(\"Confusion Matrix\")\n",
    "    print(f\"{confusion_matrix(y_test, y_pred)}\")\n",
    "    print(f\"{classification_report(y_test, y_pred)}\")\n",
    "\n",
    "print(f\"X_train {len(X_train)}, X_test {len(X_test)}, y_train {len(y_train)}, y_test {len(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850bb405-f3af-4045-862e-2e6ba28f58a0",
   "metadata": {},
   "source": [
    "We have 222 training samples and 75 testing samples with 13 numeric features and 1 binary classifier output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f08551dc-d6b9-4dc2-8ab1-31fd675a0f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[35  5]\n",
      " [ 8 27]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.81      0.88      0.84        40\n",
      "        True       0.84      0.77      0.81        35\n",
      "\n",
      "    accuracy                           0.83        75\n",
      "   macro avg       0.83      0.82      0.82        75\n",
      "weighted avg       0.83      0.83      0.83        75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=777, max_iter=2000).fit(X_train, y_train)\n",
    "score_model(model.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae369dc2-70e3-454a-98f6-ac7a55a9783b",
   "metadata": {},
   "source": [
    "We will use the overall F1-score to rank the models.  Our initial attempt got an 83%.  There is definitely a relationship, but let us see how much we can improve this model performance through feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487f76b9-0c15-4114-8e0c-09946fb9d8af",
   "metadata": {},
   "source": [
    "## Imputing NA Values\n",
    "\n",
    "There were two columns that were missing values.  Let us see what values make sense.\n",
    "\n",
    "First, let us look at `ca` (a numeric feature)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5356cd14-6d1d-4203-ae31-813ca41af13f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    299.000000\n",
       "mean       0.672241\n",
       "std        0.937438\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        0.000000\n",
       "75%        1.000000\n",
       "max        3.000000\n",
       "Name: ca, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ca.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cf697cc-e3cf-42a3-b832-20b5841bede0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ca\n",
       "0.0    176\n",
       "1.0     65\n",
       "2.0     38\n",
       "3.0     20\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ca.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012401ac-23a0-4977-b4cf-edb20723d890",
   "metadata": {},
   "source": [
    "It seems pretty safe to use 0 for these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ba0b3a5-f6ab-4dc4-b3b8-e34723948176",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ca = df.ca.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c665f3cc-f9cb-467d-87f5-6f839a81aba8",
   "metadata": {},
   "source": [
    "Now let us look at `thal` (a categorical feature)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f0d4519-74cb-41dd-9983-ad333f0445da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    301.000000\n",
       "mean       4.734219\n",
       "std        1.939706\n",
       "min        3.000000\n",
       "25%        3.000000\n",
       "50%        3.000000\n",
       "75%        7.000000\n",
       "max        7.000000\n",
       "Name: thal, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.thal.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89c85987-46e7-4f0d-bb35-a51ef120ee71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "thal\n",
       "3.0    166\n",
       "7.0    117\n",
       "6.0     18\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.thal.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15609d70-7de0-4a0d-8732-8a2bb4604446",
   "metadata": {},
   "source": [
    "It seems pretty safe to use 3 for these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83dd3866-6051-40aa-b774-febf8241b514",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.thal = df.thal.fillna(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf9eb71-a14f-40fe-a84b-68c2d4c40a0c",
   "metadata": {},
   "source": [
    "Now let us repeat our test but include all of the rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a63bbd12-3aa5-49f1-9f33-6e4c5be4f81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train 227, X_test 76, y_train 227, y_test 76\n"
     ]
    }
   ],
   "source": [
    "X = df[features].values\n",
    "y = df.disease.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=777, stratify=df.disease)\n",
    "print(f\"X_train {len(X_train)}, X_test {len(X_test)}, y_train {len(y_train)}, y_test {len(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6422ae7-78a5-41f0-bb83-7122211b2137",
   "metadata": {},
   "source": [
    "We are now using 227 rows (5 more) for training and 76 rows (1 more) for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b4cb1d0-da35-4c70-bb46-68c4759cf031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[38  3]\n",
      " [ 8 27]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.83      0.93      0.87        41\n",
      "        True       0.90      0.77      0.83        35\n",
      "\n",
      "    accuracy                           0.86        76\n",
      "   macro avg       0.86      0.85      0.85        76\n",
      "weighted avg       0.86      0.86      0.85        76\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=777, max_iter=2000).fit(X_train, y_train)\n",
    "score_model(model.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4ce2b8-2c63-4baf-9bbd-b5491b77f3eb",
   "metadata": {},
   "source": [
    "Even just include those 4 additional rows with imputed values improved the model performance to 86% (+3%)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387d879a-1546-48c0-8b7c-f6b794077cb4",
   "metadata": {},
   "source": [
    "## One-hot Encoding\n",
    "\n",
    "Many of the source columns were categorical values.  Using these as numeric features can skew the magnitude for regression, so let us one-hot encode these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42ba4a9c-6c3a-4d41-aa97-e0bf931c7848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 1he (227, 19), Testing 1he (76, 19)\n"
     ]
    }
   ],
   "source": [
    "cat_features = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'thal']\n",
    "train_df, test_df = train_test_split(df, test_size=0.25, random_state=77, stratify=df.disease)\n",
    "hot_enc = OneHotEncoder()\n",
    "hot_enc.fit(train_df[cat_features])\n",
    "train_hot = hot_enc.transform(train_df[cat_features])\n",
    "test_hot = hot_enc.transform(test_df[cat_features])\n",
    "print(f\"Training 1he {train_hot.shape}, Testing 1he {test_hot.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8aac6c2-8e4d-4663-8759-87eb9c46914d",
   "metadata": {},
   "source": [
    "So we have converted our 7 categorical features into 19 one hot encoded features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aafd333e-ed82-4ace-9565-9a2048d469be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (227, 25), X_test (76, 25), y_train (227,), y_test (76,)\n"
     ]
    }
   ],
   "source": [
    "num_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak', 'ca']\n",
    "train_num = train_df[num_features].values\n",
    "test_num = test_df[num_features].values\n",
    "X_train = sp.hstack((train_hot, train_num))\n",
    "y_train = train_df.disease.values\n",
    "X_test = sp.hstack((test_hot, test_num))\n",
    "y_test = test_df.disease.values\n",
    "print(f\"X_train {X_train.shape}, X_test {X_test.shape}, y_train {y_train.shape}, y_test {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2cec74e2-abd2-4a3c-8316-190ee20c1896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[37  4]\n",
      " [ 8 27]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.82      0.90      0.86        41\n",
      "        True       0.87      0.77      0.82        35\n",
      "\n",
      "    accuracy                           0.84        76\n",
      "   macro avg       0.85      0.84      0.84        76\n",
      "weighted avg       0.84      0.84      0.84        76\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=777, max_iter=2000).fit(X_train, y_train)\n",
    "score_model(model.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989cdcf8-12e5-42d5-ac53-18d9ea4bcb61",
   "metadata": {},
   "source": [
    "This dropped our score to 84% (+1% from base and -2% from NA test).  However, this was most likely due to scaling issues with the other numeric columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934d2177-2449-4c50-8b9f-bd8c0ea105e4",
   "metadata": {},
   "source": [
    "## Numeric Scaling\n",
    "\n",
    "Let us use the standard scalar on the remaining numeric features to ensure they have mean zero with unit variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d950fdcb-9141-4ac0-b66e-2eff785092dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[37  4]\n",
      " [ 8 27]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.82      0.90      0.86        41\n",
      "        True       0.87      0.77      0.82        35\n",
      "\n",
      "    accuracy                           0.84        76\n",
      "   macro avg       0.85      0.84      0.84        76\n",
      "weighted avg       0.84      0.84      0.84        76\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(train_num)\n",
    "train_scale = scaler.transform(train_num)\n",
    "test_scale = scaler.transform(test_num)\n",
    "X_train = sp.hstack((train_hot, train_num))\n",
    "X_test = sp.hstack((test_hot, test_num))\n",
    "model = LogisticRegression(random_state=777, max_iter=2000).fit(X_train, y_train)\n",
    "score_model(model.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1526adf5-5fec-48a9-a90c-6a4f88901a57",
   "metadata": {},
   "source": [
    "Suprisingly this did not change the score from 84%.  Perhaps we are overfitting due to the extra columns we added during one hot encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95a01c5-1a9d-486b-82c1-dcdff44bb13f",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction\n",
    "\n",
    "We are possibly overfitting our training data due to the number of columns we have.  Let us use PCA to reduce dimensionality and see how that impacts the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a8b44811-409e-4751-873b-f653f5c06786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9992013948547115\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=6, svd_solver='arpack')\n",
    "pca.fit(X_train)\n",
    "print(pca.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810bf792-16c1-4447-93e1-74bbc6fa0f01",
   "metadata": {},
   "source": [
    "So we can keep just 6 components and still explain 99.9% of the variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0f6c5ee2-9ee5-4747-abd0-a81c351c4ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (227, 6), Test (76, 6)\n"
     ]
    }
   ],
   "source": [
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "print(f\"Train {X_train_pca.shape}, Test {X_test_pca.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "df49b634-57ae-4a73-b1d0-583d441670a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[37  4]\n",
      " [ 4 31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.90      0.90      0.90        41\n",
      "        True       0.89      0.89      0.89        35\n",
      "\n",
      "    accuracy                           0.89        76\n",
      "   macro avg       0.89      0.89      0.89        76\n",
      "weighted avg       0.89      0.89      0.89        76\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=777, max_iter=2000).fit(X_train_pca, y_train)\n",
    "score_model(model.predict(X_test_pca))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb1cb7a-4af2-445f-96b7-68a81ce4d64c",
   "metadata": {},
   "source": [
    "This improved the model performance to 89% (+6% from base, +3% from previous best, and +5% from previous iteration)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33afeb53-71f2-4e2e-b479-807eab1783a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
